# 第10章：虚拟内存（第三部分）- 详细讲解

## 目录
1. [工作集模型（Working-Set Model）](#工作集模型)
2. [跟踪工作集（Keeping Track of the Working Set）](#跟踪工作集)
3. [页错误频率（Page-Fault Frequency）](#页错误频率)
4. [工作集和页错误率（Working Sets and Page Fault Rates）](#工作集和页错误率)
5. [分配内核内存（Allocating Kernel Memory）](#分配内核内存)
6. [伙伴系统（Buddy System）](#伙伴系统)
7. [Slab分配器（Slab Allocator）](#slab分配器)
8. [抖动（Thrashing）](#抖动)
9. [其他考虑（Other Considerations）](#其他考虑)
10. [操作系统示例（Operating System Examples）](#操作系统示例)
11. [非统一内存访问（Non-Uniform Memory Access, NUMA）](#非统一内存访问)

---

## 工作集模型（Working-Set Model）

### 1. 工作集模型的基本概念

#### 定义
- **Δ ≡ 工作集窗口（Working-Set Window） ≡ 固定数量的页引用**
- **例如：10,000条指令**

#### 工作集大小
- **WSSi（进程Pi的工作集） = 最近Δ中引用的页总数**
- **随时间变化**

#### 工作集窗口的选择

**① Δ太小**
- **如果Δ太小，将不会包含整个局部性**

**② Δ太大**
- **如果Δ太大，将包含多个局部性**

**③ Δ = ∞**
- **如果Δ = ∞，将包含整个程序**

### 2. 总需求帧数

#### 公式
- **D = Σ WSSi ≡ 总需求帧数**
- **局部性的近似**

#### 策略
- **如果D > m => 抖动（Thrashing）**
- **策略：如果D > m，则挂起或交换出其中一个进程**

### 3. 工作集模型的作用

#### ① 预测内存需求
- **预测进程需要多少内存**

#### ② 防止抖动
- **通过控制多道程序设计的程度**

#### ③ 优化性能
- **确保每个进程有足够的内存**

---

## 跟踪工作集（Keeping Track of the Working Set）

### 1. 跟踪工作集的方法

#### 基本方法
- **使用间隔定时器（Interval Timer）+ 引用位（Reference Bit）近似**

### 2. 基本实现

#### 示例设置
- **Δ = 10,000**
- **定时器每5000个时间单位中断一次**
- **为每个页在内存中保持2位**

#### 工作流程
- **每当定时器中断时，复制并设置所有引用位的值为0**
- **如果内存中的一位 = 1 => 页在工作集中**

#### 问题
- **为什么这不完全准确？**
- **因为只跟踪最近一个时间间隔**

### 3. 改进方法

#### 改进
- **改进 = 10位，每1000个时间单位中断一次**
- **跟踪更多历史信息**
- **更准确地确定工作集**

#### 优势
- **更准确地跟踪工作集**
- **更好地预测内存需求**

---

## 页错误频率（Page-Fault Frequency）

### 1. 页错误频率的基本概念

#### 定义
- **页错误频率（Page-Fault Frequency, PFF）**
- **比工作集模型更直接的方法**

#### 工作原理
- **建立"可接受"的页错误频率（PFF）率**
- **使用局部替换策略**

### 2. 页错误频率控制

#### ① 实际率太低
- **如果实际率太低，进程失去帧**
- **减少分配给进程的帧数**

#### ② 实际率太高
- **如果实际率太高，进程获得帧**
- **增加分配给进程的帧数**

### 3. 页错误频率的优势

#### ① 简单直接
- **比工作集模型更简单**
- **不需要跟踪工作集窗口**

#### ② 自适应
- **根据实际页错误率自动调整**
- **动态适应进程需求**

---

## 工作集和页错误率（Working Sets and Page Fault Rates）

### 1. 直接关系

#### 关系
- **进程的工作集与其页错误率之间的直接关系**
- **工作集随时间变化**
- **随时间有峰值和谷值**

### 2. 工作集变化

#### 局部性变化
- **进程从一个局部性迁移到另一个局部性**
- **局部性可能重叠**

#### 页错误率变化
- **当工作集大时，页错误率高**
- **当工作集小时，页错误率低**

### 3. 管理策略

#### 监控
- **监控工作集大小**
- **监控页错误率**

#### 调整
- **根据工作集大小调整帧分配**
- **防止抖动**

---

## 分配内核内存（Allocating Kernel Memory）

### 1. 内核内存的特点

#### 与用户内存不同
- **与用户内存不同地处理**
- **通常从空闲内存池分配**

#### 需求特点
- **内核请求不同大小的结构的内存**
- **一些内核内存需要是连续的**
- **例如：用于设备I/O**

### 2. 内核内存分配的需求

#### ① 不同大小
- **内核需要不同大小的内存块**

#### ② 连续性要求
- **某些操作需要连续内存**
- **例如：DMA操作**

#### ③ 性能要求
- **快速分配和释放**
- **最小化碎片**

---

## 伙伴系统（Buddy System）

### 1. 伙伴系统的基本概念

#### 定义
- **从固定大小的段分配内存**
- **由物理连续的页组成**
- **使用2的幂分配器分配内存**

#### 工作原理
- **以2的幂为单位满足请求**
- **请求向上舍入到下一个最高的2的幂**

### 2. 伙伴系统的工作流程

#### 分配过程
- **当需要比可用更小的分配时，当前块分成两个伙伴**
- **下一个较低的2的幂**
- **继续直到有适当大小的块可用**

#### 示例
- **例如，假设有256KB块可用，内核请求21KB**
- **分成AL和AR，每个128KB**
- **一个进一步分成BL和BR，每个64KB**
- **一个进一步分成CL和CR，每个32KB - 一个用于满足请求**

### 3. 伙伴系统的优势

#### ① 快速合并
- **优势 - 快速将未使用的块合并成更大的块**
- **伙伴可以快速合并**

#### ② 简单管理
- **管理简单**
- **只需要跟踪不同大小的块**

### 4. 伙伴系统的缺点

#### 碎片
- **缺点 - 碎片**
- **可能产生内部碎片**
- **请求大小必须向上舍入到2的幂**

---

## Slab分配器（Slab Allocator）

### 1. Slab分配器的基本概念

#### 定义
- **替代策略**
- **Slab是一个或多个物理连续的页**
- **缓存（Cache）由一个或多个slab组成**

### 2. Slab分配器的工作原理

#### ① 每个数据结构一个缓存
- **每个唯一的内核数据结构一个缓存**
- **每个缓存填充对象 - 数据结构的实例化**

#### ② 缓存创建
- **当缓存创建时，填充标记为空闲的对象**
- **当存储结构时，对象标记为已使用**

#### ③ 分配策略
- **如果slab充满已使用的对象，下一个对象从空slab分配**
- **如果没有空slab，分配新slab**

### 3. Slab分配器的优势

#### ① 无碎片
- **好处包括无碎片**
- **对象大小固定**

#### ② 快速满足
- **快速满足内存请求**
- **从预分配的缓存中分配**

#### ③ 缓存友好
- **利用CPU缓存**
- **对象连续存储**

### 4. Linux中的Slab分配器

#### 基本使用
- **例如，进程描述符是struct task_struct类型**
- **大约1.7KB内存**
- **新任务 -> 从缓存分配新struct**
- **将使用现有的空闲struct task_struct**

#### Slab状态
- **Slab可以处于三种可能的状态**：
  - **满（Full） - 全部已使用**
  - **空（Empty） - 全部空闲**
  - **部分（Partial） - 空闲和已使用的混合**

#### 分配策略
- **在请求时，slab分配器**：
  - **使用部分slab中的空闲struct**
  - **如果没有，从空slab中取一个**
  - **如果没有空slab，创建新的空slab**

### 5. Linux Slab分配器的变体

#### 历史
- **Slab从Solaris开始，现在在各种操作系统中广泛用于内核模式和用户内存**
- **Linux 2.2有SLAB，现在有SLOB和SLUB分配器**

#### ① SLOB
- **SLOB用于内存有限的系统**
- **简单块列表（Simple List of Blocks）**
- **维护3个列表对象：小、中、大对象**

#### ② SLUB
- **SLUB是性能优化的**
- **SLAB移除每CPU队列**
- **元数据存储在页结构中**

---

## 抖动（Thrashing）

### 1. 抖动的基本概念

#### 定义
- **如果进程没有"足够"的页，页错误率非常高**
- **页错误以获取页**
- **替换现有帧**
- **但很快需要被替换的帧回来**

#### 结果
- **这导致**：
  - **低CPU利用率**
  - **操作系统认为需要增加多道程序设计的程度**
  - **另一个进程添加到系统**

### 2. 抖动的过程

#### 循环
- **抖动 - 进程忙于交换页进出**
- **进程花费大部分时间等待页从磁盘加载**
- **CPU利用率低**

### 3. 需求分页和抖动

#### 为什么需求分页有效？
- **局部性模型（Locality Model）**
- **进程从一个局部性迁移到另一个局部性**
- **局部性可能重叠**

#### 为什么发生抖动？
- **Σ 局部性大小 > 总内存大小**
- **通过使用局部或优先级页替换来限制影响**

### 4. 内存引用模式中的局部性

#### 局部性特征
- **进程在短时间内访问相对较小的内存区域**
- **然后迁移到另一个局部性**
- **局部性可能重叠**

#### 局部性类型

**① 时间局部性（Temporal Locality）**
- **最近访问的页可能很快再次访问**

**② 空间局部性（Spatial Locality）**
- **附近的页可能被访问**

---

## 其他考虑（Other Considerations）

### 1. 预分页（Prepaging）

#### 目的
- **为了减少进程启动时发生的大量页错误**
- **在引用之前预分页进程将需要的所有或部分页**

#### 问题
- **但如果预分页的页未使用，I/O和内存被浪费**

#### 成本分析
- **假设s页被预分页，α的页被使用**
- **s * α保存页错误的成本 > 或 < 预分页s * (1-α)不必要页的成本？**

#### 结论
- **α接近零 => 预分页失败**
- **只有当大多数预分页的页被使用时，预分页才有效**

### 2. 页大小（Page Size）

#### 选择考虑
- **有时操作系统设计者有选择**
- **特别是在定制构建的CPU上运行时**
- **页大小选择必须考虑**：
  - **碎片（Fragmentation）**
  - **页表大小（Page Table Size）**
  - **分辨率（Resolution）**
  - **I/O开销（I/O Overhead）**
  - **页错误数（Number of Page Faults）**
  - **局部性（Locality）**
  - **TLB大小和有效性（TLB Size and Effectiveness）**

#### 常见大小
- **总是2的幂，通常在2^12（4,096字节）到2^22（4,194,304字节）范围内**
- **平均而言，随时间增长**

### 3. TLB覆盖范围（TLB Reach）

#### 定义
- **TLB覆盖范围（TLB Reach） - 从TLB可访问的内存量**
- **TLB覆盖范围 = (TLB大小) × (页大小)**

#### 理想情况
- **理想情况下，每个进程的工作集存储在TLB中**
- **否则有高度的页错误**

#### 增加页大小
- **增加页大小**
- **这可能导致碎片增加，因为并非所有应用程序都需要大页大小**

#### 提供多个页大小
- **提供多个页大小**
- **这允许需要较大页大小的应用程序有机会使用它们，而不会增加碎片**

### 4. 程序结构（Program Structure）

#### 问题示例
- **程序结构**：
```c
int[128,128] data;
```
- **每行存储在一页中**

#### 程序1（差）
```c
for (j = 0; j < 128; j++)
    for (i = 0; i < 128; i++)
        data[i,j] = 0;
```
- **128 × 128 = 16,384次页错误**
- **按列访问，每列访问导致页错误**

#### 程序2（好）
```c
for (i = 0; i < 128; i++)
    for (j = 0; j < 128; j++)
        data[i,j] = 0;
```
- **128次页错误**
- **按行访问，每行访问一次页错误**

#### 教训
- **程序结构对页错误率有重大影响**
- **应该考虑内存访问模式**

### 5. I/O互锁（I/O Interlock）

#### 定义
- **I/O互锁 - 页有时必须被锁定到内存中**

#### 需求
- **考虑I/O - 用于从设备复制文件的页必须被锁定，不能被页替换算法选择进行驱逐**
- **固定页（Pinning of Pages）以锁定到内存中**

#### 原因
- **防止在I/O操作期间页被替换**
- **确保I/O操作完成**

---

## 操作系统示例（Operating System Examples）

### 1. Windows

#### 需求分页
- **使用带集群（Clustering）的需求分页**
- **集群带来故障页周围的页**

#### 工作集管理
- **进程被分配工作集最小值和工作集最大值**
- **工作集最小值是进程保证在内存中拥有的最小页数**
- **进程可能被分配多达其工作集最大值的页**

#### 自动工作集修剪
- **当系统中的空闲内存量低于阈值时，执行自动工作集修剪以恢复空闲内存量**
- **工作集修剪从超过其工作集最小值的进程移除页**

### 2. Solaris

#### 空闲页列表
- **维护空闲页列表以分配给故障进程**
- **Lotsfree - 阈值参数（空闲内存量）以开始分页**
- **Desfree - 阈值参数以增加分页**
- **Minfree - 阈值参数以开始交换**

#### 分页过程
- **分页由pageout进程执行**
- **Pageout使用修改的时钟算法扫描页**
- **Scanrate是扫描页的速率**
- **这范围从slowscan到fastscan**
- **Pageout根据可用空闲内存量更频繁地调用**

#### 优先级分页
- **优先级分页给进程代码页优先级**
- **优先保留代码页**

---

## 非统一内存访问（Non-Uniform Memory Access, NUMA）

### 1. NUMA的基本概念

#### 假设
- **到目前为止，我们假设所有内存访问相等**
- **许多系统是NUMA - 访问内存的速度不同**

#### 系统架构
- **考虑包含CPU和内存的系统板，通过系统总线互连**
- **NUMA多处理架构**

### 2. NUMA的性能优化

#### 最优性能
- **最优性能来自在调度线程的CPU"附近"分配内存**
- **并修改调度器以在可能时在同一系统板上调度线程**

#### Solaris解决方案
- **通过创建lgroups（本地组）解决**
- **跟踪CPU/内存低延迟组的结构**
- **由调度器和分页器使用**

#### 策略
- **在可能时，在同一lgroup中调度进程的所有线程并为该进程分配所有内存**
- **减少内存访问延迟**

---

## 总结

### 关键概念回顾

1. **工作集模型**：
   - 工作集窗口Δ
   - 工作集大小WSS
   - 总需求帧数D
   - 防止抖动的策略

2. **跟踪工作集**：
   - 间隔定时器+引用位
   - 改进方法使用更多位

3. **页错误频率**：
   - 比工作集模型更直接
   - 根据实际率自动调整

4. **工作集和页错误率**：
   - 直接关系
   - 随时间变化

5. **内核内存分配**：
   - 与用户内存不同
   - 需要连续内存
   - 不同大小

6. **伙伴系统**：
   - 2的幂分配
   - 快速合并
   - 但可能有碎片

7. **Slab分配器**：
   - 无碎片
   - 快速满足
   - Linux中的变体

8. **抖动**：
   - 高页错误率
   - 低CPU利用率
   - 局部性模型

9. **预分页**：
   - 减少启动时的页错误
   - 但可能浪费内存

10. **页大小**：
    - 多种考虑因素
    - 多个页大小

11. **TLB覆盖范围**：
    - TLB大小×页大小
    - 理想情况下包含工作集

12. **程序结构**：
    - 对页错误率有重大影响
    - 应该考虑访问模式

13. **I/O互锁**：
    - 锁定页到内存
    - 防止I/O期间的替换

14. **操作系统示例**：
    - Windows：工作集管理
    - Solaris：pageout进程

15. **NUMA**：
    - 非统一内存访问
    - 性能优化策略

### 学习要点

#### 必须理解的概念

1. **工作集模型**：
   - 如何跟踪工作集
   - 如何防止抖动

2. **抖动**：
   - 为什么发生
   - 如何防止

3. **内核内存分配**：
   - 伙伴系统vs Slab分配器
   - 各自的优缺点

4. **性能优化**：
   - 预分页
   - 页大小选择
   - TLB覆盖范围

5. **程序结构**：
   - 如何影响页错误率
   - 如何优化

### 实际应用

- **理解现代内存管理**：工作集模型和抖动防止
- **理解性能优化**：如何选择页大小和优化TLB
- **理解内核设计**：内核内存分配策略
- **理解系统调优**：如何防止抖动
- **理解NUMA系统**：如何优化内存访问

### 思考题

1. **什么是工作集？**
   - 最近Δ中引用的页集合
   - 随时间变化

2. **什么是抖动？**
   - 高页错误率导致低CPU利用率
   - 进程忙于交换页

3. **伙伴系统和Slab分配器的区别是什么？**
   - 伙伴系统：2的幂，可能有碎片
   - Slab分配器：固定大小，无碎片

4. **为什么程序结构对页错误率有影响？**
   - 访问模式影响局部性
   - 按行访问比按列访问好

5. **如何防止抖动？**
   - 使用工作集模型
   - 控制多道程序设计的程度
   - 使用局部替换

---

*希望这个详细讲解能帮助你更好地理解虚拟内存的第三部分内容！如果有任何不清楚的地方，可以随时提问。*

